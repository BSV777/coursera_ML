{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "630aa407",
   "metadata": {},
   "source": [
    "В задачах классификации может быть много особенностей, влияющих на подсчет качества: различные цены ошибок, несбалансированность классов и т.д. Из-за этого существует большое количество метрик качества — каждая из них рассчитана на определенное сочетание свойств задачи и требований к ее решению.\n",
    "\n",
    "Меры качества классификации можно разбить на две большие группы: предназначенные для алгоритмов, выдающих номера классов, и для алгоритмов, выдающих оценки принадлежности к классам. К первой группе относятся доля правильных ответов, точность, полнота, F-мера. Ко второй — площади под ROC- или PR-кривой.\n",
    "Реализация в sklearn\n",
    "\n",
    "Различные метрики качества реализованы в пакете sklearn.metrics. Конкретные функции указаны в инструкции по выполнению задания.\n",
    "\n",
    "1. Загрузите файл classification.csv. В нем записаны истинные классы объектов выборки (колонка true) и ответы некоторого классификатора (колонка pred).\n",
    "\n",
    "2. Заполните таблицу ошибок классификации:\n",
    "\n",
    "Для этого подсчитайте величины TP, FP, FN и TN согласно их определениям. Например, FP — это количество объектов, имеющих класс 0, но отнесенных алгоритмом к классу 1. Ответ в данном вопросе — четыре числа через пробел.\n",
    "\n",
    "3. Посчитайте основные метрики качества классификатора:\n",
    "\n",
    "    Accuracy (доля верно угаданных) — sklearn.metrics.accuracy_score\n",
    "\n",
    "    Precision (точность) — sklearn.metrics.precision_score\n",
    "\n",
    "    Recall (полнота) — sklearn.metrics.recall_score\n",
    "\n",
    "    F-мера — sklearn.metrics.f1_score\n",
    "\n",
    "В качестве ответа укажите эти четыре числа через пробел.\n",
    "\n",
    "4. Имеется четыре обученных классификатора. В файле scores.csv записаны истинные классы и значения степени принадлежности положительному классу для каждого классификатора на некоторой выборке:\n",
    "\n",
    "    для логистической регрессии — вероятность положительного класса (колонка score_logreg),\n",
    "\n",
    "    для SVM — отступ от разделяющей поверхности (колонка score_svm),\n",
    "\n",
    "    для метрического алгоритма — взвешенная сумма классов соседей (колонка score_knn),\n",
    "\n",
    "    для решающего дерева — доля положительных объектов в листе (колонка score_tree).\n",
    "\n",
    "Загрузите этот файл.\n",
    "\n",
    "5. Посчитайте площадь под ROC-кривой для каждого классификатора. Какой классификатор имеет наибольшее значение метрики AUC-ROC (укажите название столбца)? Воспользуйтесь функцией sklearn.metrics.roc_auc_score.\n",
    "\n",
    "6. Какой классификатор достигает наибольшей точности (Precision) при полноте (Recall) не менее 70% ? \n",
    "\n",
    "Чтобы получить ответ на этот вопрос, найдите все точки precision-recall-кривой с помощью функции sklearn.metrics.precision_recall_curve. Она возвращает три массива: precision, recall, thresholds. В них записаны точность и полнота при определенных порогах, указанных в массиве thresholds. Найдите максимальной значение точности среди тех записей, для которых полнота не меньше, чем 0.7.\n",
    "\n",
    "Если ответом является нецелое число, то целую и дробную часть необходимо разграничивать точкой, например, 0.42. При необходимости округляйте дробную часть до двух знаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3216713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e814817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('classification.csv', sep=',')\n",
    "y_true = df.values[:, 0]\n",
    "y_pred = df.values[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33defd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = df[(df.true==1) & (df.pred==1)].shape[0]\n",
    "FP = df[(df.true==0) & (df.pred==1)].shape[0]\n",
    "FN = df[(df.true==1) & (df.pred==0)].shape[0]\n",
    "TN = df[(df.true==0) & (df.pred==0)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb45be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 34 59 64\n"
     ]
    }
   ],
   "source": [
    "answer = f'%d %d %d %d' % (TP, FP, FN, TN)\n",
    "print(answer)\n",
    "with open('lab9_1.txt', 'w') as outfile:\n",
    "    outfile.write(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e11e2c",
   "metadata": {},
   "source": [
    "Accuracy (доля верно угаданных) — sklearn.metrics.accuracy_score\n",
    "sklearn.metrics.accuracy_score(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    *,\n",
    "    normalize=True,\n",
    "    sample_weight=None,\n",
    ")\n",
    "\n",
    "Precision (точность) — sklearn.metrics.precision_score\n",
    "sklearn.metrics.precision_score(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    *,\n",
    "    labels=None,\n",
    "    pos_label=1,\n",
    "    average='binary',\n",
    "    sample_weight=None,\n",
    "    zero_division='warn',\n",
    ")\n",
    "Recall (полнота) — sklearn.metrics.recall_score\n",
    "sklearn.metrics.recall_score(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    *,\n",
    "    labels=None,\n",
    "    pos_label=1,\n",
    "    average='binary',\n",
    "    sample_weight=None,\n",
    "    zero_division='warn',\n",
    ")\n",
    "F-мера — sklearn.metrics.f1_score\n",
    "sklearn.metrics.f1_score(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    *,\n",
    "    labels=None,\n",
    "    pos_label=1,\n",
    "    average='binary',\n",
    "    sample_weight=None,\n",
    "    zero_division='warn',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d712ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "precision = sklearn.metrics.precision_score(y_true, y_pred)\n",
    "\n",
    "recall = sklearn.metrics.recall_score(y_true, y_pred)\n",
    "\n",
    "f_mera = sklearn.metrics.f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced1542a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54 0.56 0.42 0.48\n"
     ]
    }
   ],
   "source": [
    "answer = f'%s %s %s %s' % (round(accuracy,2), round(precision,2), round(recall,2), round(f_mera,2))\n",
    "print(answer)\n",
    "with open('lab9_2.txt', 'w') as outfile:\n",
    "    outfile.write(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337f7804",
   "metadata": {},
   "source": [
    "4. Имеется четыре обученных классификатора. В файле scores.csv записаны истинные классы и значения степени принадлежности положительному классу для каждого классификатора на некоторой выборке:\n",
    "\n",
    "    для логистической регрессии — вероятность положительного класса (колонка score_logreg),\n",
    "\n",
    "    для SVM — отступ от разделяющей поверхности (колонка score_svm),\n",
    "\n",
    "    для метрического алгоритма — взвешенная сумма классов соседей (колонка score_knn),\n",
    "\n",
    "    для решающего дерева — доля положительных объектов в листе (колонка score_tree).\n",
    "\n",
    "Загрузите этот файл.\n",
    "\n",
    "5. Посчитайте площадь под ROC-кривой для каждого классификатора. Какой классификатор имеет наибольшее значение метрики AUC-ROC (укажите название столбца)? Воспользуйтесь функцией sklearn.metrics.roc_auc_score.\n",
    "\n",
    "Какой из классификаторов имеет наибольшее значение метрики AUC-ROC (укажите название столбца)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e4fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('scores.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c33d1dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>score_logreg</th>\n",
       "      <th>score_svm</th>\n",
       "      <th>score_knn</th>\n",
       "      <th>score_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.683832</td>\n",
       "      <td>0.145976</td>\n",
       "      <td>0.787063</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.801966</td>\n",
       "      <td>0.239511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.382315</td>\n",
       "      <td>-0.245701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.506797</td>\n",
       "      <td>-0.137058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.488781</td>\n",
       "      <td>-0.154148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0.573801</td>\n",
       "      <td>-0.088203</td>\n",
       "      <td>0.284192</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0.624422</td>\n",
       "      <td>-0.012315</td>\n",
       "      <td>0.205437</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>0.425538</td>\n",
       "      <td>-0.135673</td>\n",
       "      <td>0.382351</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>0.905270</td>\n",
       "      <td>0.583806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>0.275594</td>\n",
       "      <td>-0.422160</td>\n",
       "      <td>0.743567</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     true  score_logreg  score_svm  score_knn  score_tree\n",
       "0       0      0.683832   0.145976   0.787063    0.500000\n",
       "1       1      0.801966   0.239511   1.000000    0.833333\n",
       "2       0      0.382315  -0.245701   0.000000    0.000000\n",
       "3       1      0.506797  -0.137058   0.000000    0.105263\n",
       "4       1      0.488781  -0.154148   0.000000    0.105263\n",
       "..    ...           ...        ...        ...         ...\n",
       "195     0      0.573801  -0.088203   0.284192    0.400000\n",
       "196     0      0.624422  -0.012315   0.205437    0.400000\n",
       "197     1      0.425538  -0.135673   0.382351    0.700000\n",
       "198     0      0.905270   0.583806   1.000000    1.000000\n",
       "199     0      0.275594  -0.422160   0.743567    0.642857\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d587e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.roc_auc_score?\n",
    "\n",
    "sklearn.metrics.roc_auc_score(\n",
    "    y_true,\n",
    "    y_score,\n",
    "    *,\n",
    "    average='macro',\n",
    "    sample_weight=None,\n",
    "    max_fpr=None,\n",
    "    multi_class='raise',\n",
    "    labels=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0ccbb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.719187675070028, 'score_logreg'], [0.7086834733893557, 'score_svm'], [0.6351540616246498, 'score_knn'], [0.6919267707082833, 'score_tree']]\n"
     ]
    }
   ],
   "source": [
    "score_list=[]\n",
    "score_list.append([sklearn.metrics.roc_auc_score(df.true, df.score_logreg), \"score_logreg\"])\n",
    "score_list.append([sklearn.metrics.roc_auc_score(df.true, df.score_svm), \"score_svm\"])\n",
    "score_list.append([sklearn.metrics.roc_auc_score(df.true, df.score_knn), \"score_knn\"])\n",
    "score_list.append([sklearn.metrics.roc_auc_score(df.true, df.score_tree), \"score_tree\"])\n",
    "print(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25698f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'score_logreg'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.argmax?\n",
    "score_list[np.argmax(score_list, axis=0)[0]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99cb06a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_logreg\n"
     ]
    }
   ],
   "source": [
    "answer = score_list[np.argmax(score_list, axis=0)[0]][1]\n",
    "print(answer)\n",
    "with open('lab9_3.txt', 'w') as outfile:\n",
    "    outfile.write(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f87452a",
   "metadata": {},
   "source": [
    "6. Какой классификатор достигает наибольшей точности (Precision) при полноте (Recall) не менее 70% ? \n",
    "\n",
    "Чтобы получить ответ на этот вопрос, найдите все точки precision-recall-кривой с помощью функции sklearn.metrics.precision_recall_curve. Она возвращает три массива: precision, recall, thresholds. В них записаны точность и полнота при определенных порогах, указанных в массиве thresholds. Найдите максимальной значение точности среди тех записей, для которых полнота не меньше, чем 0.7.\n",
    "Какой классификатор достигает наибольшей точности при полноте не менее 70% (укажите название столбца)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfb50a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.precision_recall_curve?\n",
    "# sklearn.metrics.precision_recall_curve(\n",
    "#     y_true,\n",
    "#     probas_pred,\n",
    "#     *,\n",
    "#     pos_label=None,\n",
    "#     sample_weight=None,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65734126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision, recall, thresholds = sklearn.metrics.precision_recall_curve(df.true, df.score_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3528d91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision     [0.49746192893401014, 0.49489795918367346, 0.4...\n",
       "recall        [1.0, 0.9897959183673469, 0.9795918367346939, ...\n",
       "thresholds    [0.0707387218281469, 0.074923336628734, 0.0866...\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pr_curve = pd.Series(sklearn.metrics.precision_recall_curve(df.true, df.score_logreg))\n",
    "# pr_curve.index = [\"precision\", \"recall\", \"thresholds\"]\n",
    "# pr_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0715a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr_curve_score_logreg = pd.DataFrame(sklearn.metrics.precision_recall_curve(df.true, df.score_logreg), \n",
    "                           [\"precision\", \"recall\", \"thresholds\"]).T\n",
    "df_pr_curve_score_svm = pd.DataFrame(sklearn.metrics.precision_recall_curve(df.true, df.score_svm), \n",
    "                           [\"precision\", \"recall\", \"thresholds\"]).T\n",
    "df_pr_curve_score_knn = pd.DataFrame(sklearn.metrics.precision_recall_curve(df.true, df.score_knn), \n",
    "                           [\"precision\", \"recall\", \"thresholds\"]).T\n",
    "df_pr_curve_score_tree = pd.DataFrame(sklearn.metrics.precision_recall_curve(df.true, df.score_tree), \n",
    "                           [\"precision\", \"recall\", \"thresholds\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e991e6",
   "metadata": {},
   "source": [
    "Найдите max precision среди тех записей, для которых recall>=0.7. \n",
    "Какой классификатор достигает наибольшей точности при полноте не менее 70% (укажите название столбца)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b6d4769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6302521008403361, 'score_logreg'], [0.6228070175438597, 'score_svm'], [0.6065573770491803, 'score_knn'], [0.6517857142857143, 'score_tree']]\n"
     ]
    }
   ],
   "source": [
    "score_list=[]\n",
    "score_list.append([df_pr_curve_score_logreg[df_pr_curve_score_logreg.recall>=0.7].precision.max(), \"score_logreg\"])\n",
    "score_list.append([df_pr_curve_score_svm[df_pr_curve_score_svm.recall>=0.7].precision.max(), \"score_svm\"])\n",
    "score_list.append([df_pr_curve_score_knn[df_pr_curve_score_knn.recall>=0.7].precision.max(), \"score_knn\"])\n",
    "score_list.append([df_pr_curve_score_tree[df_pr_curve_score_tree.recall>=0.7].precision.max(), \"score_tree\"])\n",
    "print(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e04f1a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_tree\n"
     ]
    }
   ],
   "source": [
    "answer = score_list[np.argmax(score_list, axis=0)[0]][1]\n",
    "print(answer)\n",
    "with open('lab9_4.txt', 'w') as outfile:\n",
    "    outfile.write(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
