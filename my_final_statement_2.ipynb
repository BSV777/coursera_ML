{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предметная область: Игра Dota 2\n",
    "\n",
    "[Dota 2](https://ru.wikipedia.org/wiki/Dota_2) — многопользовательская компьютерная игра жанра [MOBA](https://ru.wikipedia.org/wiki/MOBA). Игроки играют между собой матчи. В каждом матче участвует две команды, 5 человек в каждой. Одна команда играет за светлую сторону (The Radiant), другая — за тёмную (The Dire). Цель каждой команды — уничтожить главное здание базы противника (трон).\n",
    "\n",
    "\n",
    "#### 1. Игроки выбирают героев\n",
    "\n",
    "Всего в игре чуть более 100 различных героев (персонажей). В начале игры, команды в определенном порядке выбирают героев себе и запрещают выбирать определенных героев противнику (баны). Каждый игрок будет управлять одним героем, в рамках одного матча не может быть несколько одинаковых героев.  Герои различаются между собой своими характеристиками и способностями. От комбинации выбранных героев во многом зависит успех команды.\n",
    "\n",
    "\n",
    "#### 2. Основная часть\n",
    "\n",
    "Игроки могут получать золото и опыт за убийство чужих героев или прочих юнитов. Накопленный опыт влияет на уровень героя, который в свою очередь позволяет улучшать способности. За накопленное золото игроки покупают предметы, которые улучшают характеристики героев или дают им новые способности.\n",
    "\n",
    "После смерти герой отправляется в \"таверну\" и возрождается только по прошествии некоторого времени, таким образом команда на некоторое время теряет игрока, однако игрок может досрочно выкупить героя из таверны за определенную сумму золота.\n",
    "\n",
    "В течение игры команды развивают своих героев, обороняют свою часть поля и нападают на вражескую.\n",
    "\n",
    "\n",
    "#### 3. Конец игры\n",
    "\n",
    "Игра заканчивается, когда одна из команд разрушет определенное число \"башен\" противника и уничтожает трон.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача: предсказание победы по данным о первых 5 минутах игры\n",
    "\n",
    "По первым 5 минутам игры предсказать, какая из команд победит: Radiant или Dire?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Описание признаков в таблице\n",
    "\n",
    "- `match_id`: идентификатор матча в наборе данных\n",
    "- `start_time`: время начала матча (unixtime)\n",
    "- `lobby_type`: тип комнаты, в которой собираются игроки (расшифровка в `dictionaries/lobbies.csv`)\n",
    "- Наборы признаков для каждого игрока (игроки команды Radiant — префикс `rN`, Dire — `dN`):\n",
    "    - `r1_hero`: герой игрока (расшифровка в dictionaries/heroes.csv)\n",
    "    - `r1_level`: максимальный достигнутый уровень героя (за первые 5 игровых минут)\n",
    "    - `r1_xp`: максимальный полученный опыт\n",
    "    - `r1_gold`: достигнутая ценность героя\n",
    "    - `r1_lh`: число убитых юнитов\n",
    "    - `r1_kills`: число убитых игроков\n",
    "    - `r1_deaths`: число смертей героя\n",
    "    - `r1_items`: число купленных предметов\n",
    "- Признаки события \"первая кровь\" (first blood). Если событие \"первая кровь\" не успело произойти за первые 5 минут, то признаки принимают пропущенное значение\n",
    "    - `first_blood_time`: игровое время первой крови\n",
    "    - `first_blood_team`: команда, совершившая первую кровь (0 — Radiant, 1 — Dire)\n",
    "    - `first_blood_player1`: игрок, причастный к событию\n",
    "    - `first_blood_player2`: второй игрок, причастный к событию\n",
    "- Признаки для каждой команды (префиксы `radiant_` и `dire_`)\n",
    "    - `radiant_bottle_time`: время первого приобретения командой предмета \"bottle\"\n",
    "    - `radiant_courier_time`: время приобретения предмета \"courier\" \n",
    "    - `radiant_flying_courier_time`: время приобретения предмета \"flying_courier\" \n",
    "    - `radiant_tpscroll_count`: число предметов \"tpscroll\" за первые 5 минут\n",
    "    - `radiant_boots_count`: число предметов \"boots\"\n",
    "    - `radiant_ward_observer_count`: число предметов \"ward_observer\"\n",
    "    - `radiant_ward_sentry_count`: число предметов \"ward_sentry\"\n",
    "    - `radiant_first_ward_time`: время установки командой первого \"наблюдателя\", т.е. предмета, который позволяет видеть часть игрового поля\n",
    "- Итог матча (данные поля отсутствуют в тестовой выборке, поскольку содержат информацию, выходящую за пределы первых 5 минут матча)\n",
    "    - `duration`: длительность\n",
    "    - `radiant_win`: 1, если победила команда Radiant, 0 — иначе\n",
    "    - Состояние башен и барраков к концу матча (см. описание полей набора данных)\n",
    "        - `tower_status_radiant`\n",
    "        - `tower_status_dire`\n",
    "        - `barracks_status_radiant`\n",
    "        - `barracks_status_dire`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чтение файла с признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape:  (97230, 108)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>r1_hero</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_items</th>\n",
       "      <th>...</th>\n",
       "      <th>dire_boots_count</th>\n",
       "      <th>dire_ward_observer_count</th>\n",
       "      <th>dire_ward_sentry_count</th>\n",
       "      <th>dire_first_ward_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>radiant_win</th>\n",
       "      <th>tower_status_radiant</th>\n",
       "      <th>tower_status_dire</th>\n",
       "      <th>barracks_status_radiant</th>\n",
       "      <th>barracks_status_dire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430198770</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2098</td>\n",
       "      <td>1489</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>2874</td>\n",
       "      <td>1</td>\n",
       "      <td>1796</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1430220345</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>1188</td>\n",
       "      <td>1033</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2463</td>\n",
       "      <td>1</td>\n",
       "      <td>1974</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1430227081</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>1319</td>\n",
       "      <td>1270</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1830</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1430263531</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1779</td>\n",
       "      <td>1056</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1459</td>\n",
       "      <td>0</td>\n",
       "      <td>1920</td>\n",
       "      <td>2047</td>\n",
       "      <td>50</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1430282290</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1431</td>\n",
       "      <td>1090</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>2449</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1974</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          start_time  lobby_type  r1_hero  r1_level  r1_xp  r1_gold  r1_lh  \\\n",
       "match_id                                                                     \n",
       "0         1430198770           7       11         5   2098     1489     20   \n",
       "1         1430220345           0       42         4   1188     1033      9   \n",
       "2         1430227081           7       33         4   1319     1270     22   \n",
       "3         1430263531           1       29         4   1779     1056     14   \n",
       "4         1430282290           7       13         4   1431     1090      8   \n",
       "\n",
       "          r1_kills  r1_deaths  r1_items  ...  dire_boots_count  \\\n",
       "match_id                                 ...                     \n",
       "0                0          0         7  ...                 4   \n",
       "1                0          1        12  ...                 4   \n",
       "2                0          0        12  ...                 4   \n",
       "3                0          0         5  ...                 4   \n",
       "4                1          0         8  ...                 3   \n",
       "\n",
       "          dire_ward_observer_count  dire_ward_sentry_count  \\\n",
       "match_id                                                     \n",
       "0                                2                       2   \n",
       "1                                3                       1   \n",
       "2                                3                       1   \n",
       "3                                2                       0   \n",
       "4                                3                       0   \n",
       "\n",
       "          dire_first_ward_time  duration  radiant_win  tower_status_radiant  \\\n",
       "match_id                                                                      \n",
       "0                        -52.0      2874            1                  1796   \n",
       "1                         -5.0      2463            1                  1974   \n",
       "2                         13.0      2130            0                     0   \n",
       "3                         27.0      1459            0                  1920   \n",
       "4                        -16.0      2449            0                     4   \n",
       "\n",
       "          tower_status_dire  barracks_status_radiant  barracks_status_dire  \n",
       "match_id                                                                    \n",
       "0                         0                       51                     0  \n",
       "1                         0                       63                     1  \n",
       "2                      1830                        0                    63  \n",
       "3                      2047                       50                    63  \n",
       "4                      1974                        3                    63  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('data/features.csv', index_col='match_id')\n",
    "objects_count = features.shape[0]\n",
    "print(\"features.shape: \", features.shape)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка исходных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление признаков, связанных с итогами матча (они помечены в описании данных как отсутствующие в тестовой выборке).\n",
    "    \n",
    "- `duration`: длительность\n",
    "- `radiant_win`: 1, если победила команда Radiant, 0 — иначе\n",
    "- Состояние башен и барраков к концу матча (см. описание полей набора данных)\n",
    "    - `tower_status_radiant`\n",
    "    - `tower_status_dire`\n",
    "    - `barracks_status_radiant`\n",
    "    - `barracks_status_dire`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (97230, 102)\n",
      "y_train.shape:  (97230,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>r1_hero</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_items</th>\n",
       "      <th>...</th>\n",
       "      <th>radiant_ward_sentry_count</th>\n",
       "      <th>radiant_first_ward_time</th>\n",
       "      <th>dire_bottle_time</th>\n",
       "      <th>dire_courier_time</th>\n",
       "      <th>dire_flying_courier_time</th>\n",
       "      <th>dire_tpscroll_count</th>\n",
       "      <th>dire_boots_count</th>\n",
       "      <th>dire_ward_observer_count</th>\n",
       "      <th>dire_ward_sentry_count</th>\n",
       "      <th>dire_first_ward_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430198770</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2098</td>\n",
       "      <td>1489</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1430220345</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>1188</td>\n",
       "      <td>1033</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1430227081</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>1319</td>\n",
       "      <td>1270</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-77.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1430263531</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1779</td>\n",
       "      <td>1056</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1430282290</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1431</td>\n",
       "      <td>1090</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          start_time  lobby_type  r1_hero  r1_level  r1_xp  r1_gold  r1_lh  \\\n",
       "match_id                                                                     \n",
       "0         1430198770           7       11         5   2098     1489     20   \n",
       "1         1430220345           0       42         4   1188     1033      9   \n",
       "2         1430227081           7       33         4   1319     1270     22   \n",
       "3         1430263531           1       29         4   1779     1056     14   \n",
       "4         1430282290           7       13         4   1431     1090      8   \n",
       "\n",
       "          r1_kills  r1_deaths  r1_items  ...  radiant_ward_sentry_count  \\\n",
       "match_id                                 ...                              \n",
       "0                0          0         7  ...                          0   \n",
       "1                0          1        12  ...                          0   \n",
       "2                0          0        12  ...                          1   \n",
       "3                0          0         5  ...                          0   \n",
       "4                1          0         8  ...                          0   \n",
       "\n",
       "          radiant_first_ward_time  dire_bottle_time  dire_courier_time  \\\n",
       "match_id                                                                 \n",
       "0                            35.0             103.0              -84.0   \n",
       "1                           -20.0             149.0              -84.0   \n",
       "2                           -39.0              45.0              -77.0   \n",
       "3                           -30.0             124.0              -80.0   \n",
       "4                            46.0             182.0              -80.0   \n",
       "\n",
       "          dire_flying_courier_time  dire_tpscroll_count  dire_boots_count  \\\n",
       "match_id                                                                    \n",
       "0                            221.0                    3                 4   \n",
       "1                            195.0                    5                 4   \n",
       "2                            221.0                    3                 4   \n",
       "3                            184.0                    0                 4   \n",
       "4                            225.0                    6                 3   \n",
       "\n",
       "          dire_ward_observer_count  dire_ward_sentry_count  \\\n",
       "match_id                                                     \n",
       "0                                2                       2   \n",
       "1                                3                       1   \n",
       "2                                3                       1   \n",
       "3                                2                       0   \n",
       "4                                3                       0   \n",
       "\n",
       "          dire_first_ward_time  \n",
       "match_id                        \n",
       "0                        -52.0  \n",
       "1                         -5.0  \n",
       "2                         13.0  \n",
       "3                         27.0  \n",
       "4                        -16.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = features.drop(['duration', 'radiant_win', 'tower_status_radiant', \n",
    "                          'tower_status_dire', 'barracks_status_radiant', 'barracks_status_dire'], axis = 1)\n",
    "X_train_ver2 = X_train.copy()\n",
    "\n",
    "features_count = X_train.shape[1]\n",
    "\n",
    "y_train = features['radiant_win'].astype('int32')\n",
    "#y_train = features['radiant_win']\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте выборку на наличие пропусков с помощью функции count(), которая для каждого столбца показывает число заполненных значений. Много ли пропусков в данных? Запишите названия признаков, имеющих пропуски, и попробуйте для любых двух из них дать обоснование, почему их значения могут быть пропущены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Count]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = pd.DataFrame(X_train.count(), columns=['Count'])\n",
    "cnt[cnt['Count'] < objects_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если соответствующие события не успели произойти за первые 5 минут, то признаки принимают пропущенное значение:\n",
    "\n",
    "    - `first_blood_time`: игровое время первой крови\n",
    "    - `first_blood_team`: команда, совершившая первую кровь (0 — Radiant, 1 — Dire)\n",
    "    - `first_blood_player1`: игрок, причастный к событию\n",
    "    - `first_blood_player2`: второй игрок, причастный к событию\n",
    "- Признаки для каждой команды (префиксы `radiant_` и `dire_`)\n",
    "    - `radiant_bottle_time`: время первого приобретения командой предмета \"bottle\"\n",
    "    - `radiant_courier_time`: время приобретения предмета \"courier\" \n",
    "    - `radiant_flying_courier_time`: время приобретения предмета \"flying_courier\" \n",
    "    - `radiant_first_ward_time`: время установки командой первого \"наблюдателя\", т.е. предмета, который позволяет видеть часть игрового поля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подход 1: градиентный бустинг \"в лоб\"\n",
    "Один из самых универсальных алгоритмов, изученных в нашем курсе, является градиентный бустинг. Он не очень требователен к данным, восстанавливает нелинейные зависимости, и хорошо работает на многих наборах данных, что и обуславливает его популярность. Вполне разумной мыслью будет попробовать именно его в первую очередь.\n",
    "\n",
    "1. **DONE**: Считайте таблицу с признаками из файла features.csv с помощью кода, приведенного выше. Удалите признаки, связанные с итогами матча (они помечены в описании данных как отсутствующие в тестовой выборке).\n",
    "2. **DONE**: Проверьте выборку на наличие пропусков с помощью функции count(), которая для каждого столбца показывает число заполненных значений. Много ли пропусков в данных? Запишите названия признаков, имеющих пропуски, и попробуйте для любых двух из них дать обоснование, почему их значения могут быть пропущены.\n",
    "3. **DONE**: Замените пропуски на нули с помощью функции fillna(). На самом деле этот способ является предпочтительным для логистической регрессии, поскольку он позволит пропущенному значению не вносить никакого вклада в предсказание. Для деревьев часто лучшим вариантом оказывается замена пропуска на очень большое или очень маленькое значение — в этом случае при построении разбиения вершины можно будет отправить объекты с пропусками в отдельную ветвь дерева. Также есть и другие подходы — например, замена пропуска на среднее значение признака. Мы не требуем этого в задании, но при желании попробуйте разные подходы к обработке пропусков и сравните их между собой.\n",
    "3. **DONE**: Какой столбец содержит целевую переменную? Запишите его название.\n",
    "4. **DONE**: Забудем, что в выборке есть категориальные признаки, и попробуем обучить градиентный бустинг над деревьями на имеющейся матрице \"объекты-признаки\". Зафиксируйте генератор разбиений для кросс-валидации по 5 блокам (KFold), не забудьте перемешать при этом выборку (shuffle=True), поскольку данные в таблице отсортированы по времени, и без перемешивания можно столкнуться с нежелательными эффектами при оценивании качества. Оцените качество градиентного бустинга (GradientBoostingClassifier) с помощью данной кросс-валидации, попробуйте при этом разное количество деревьев (как минимум протестируйте следующие значения для количества деревьев: 10, 20, 30). Долго ли настраивались классификаторы? Достигнут ли оптимум на испытанных значениях параметра n_estimators, или же качество, скорее всего, продолжит расти при дальнейшем его увеличении?\n",
    "\n",
    "##### Что указать в отчете\n",
    "В отчете по данному этапу вы должны ответить на следующие вопросы:\n",
    "1. Какие признаки имеют пропуски среди своих значений? Что могут означать пропуски в этих признаках (ответьте на этот вопрос для двух любых признаков)?\n",
    "2. Как называется столбец, содержащий целевую переменную?\n",
    "3. Как долго проводилась кросс-валидация для градиентного бустинга с 30 деревьями? Какое качество при этом получилось? Напомним, что в данном задании мы используем метрику качества AUC-ROC.\n",
    "4. Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? Что бы вы предложили делать, чтобы ускорить его обучение при увеличении количества деревьев?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замените пропуски на нули с помощью функции fillna(). На самом деле этот способ является предпочтительным для логистической регрессии, поскольку он позволит пропущенному значению не вносить никакого вклада в предсказание. Для деревьев часто лучшим вариантом оказывается замена пропуска на очень большое или очень маленькое значение — в этом случае при построении разбиения вершины можно будет отправить объекты с пропусками в отдельную ветвь дерева. \n",
    "\n",
    "Также есть и другие подходы — например, замена пропуска на среднее значение признака. Мы не требуем этого в задании, но при желании попробуйте разные подходы к обработке пропусков и сравните их между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_with_na = cnt[cnt['Count'] < objects_count].index\n",
    "for field in fields_with_na:\n",
    "    X_train_ver2[field].fillna(X_train_ver2[field].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой столбец содержит целевую переменную? Запишите его название.\n",
    "\n",
    "**radiant_win**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забудем, что в выборке есть категориальные признаки, и попробуем обучить градиентный бустинг над деревьями на имеющейся матрице \"объекты-признаки\". \n",
    "\n",
    "Зафиксируйте генератор разбиений для кросс-валидации по 5 блокам (KFold), не забудьте перемешать при этом выборку (shuffle=True), поскольку данные в таблице отсортированы по времени, и без перемешивания можно столкнуться с нежелательными эффектами при оценивании качества. \n",
    "\n",
    "Оцените качество градиентного бустинга (GradientBoostingClassifier) с помощью данной кросс-валидации, попробуйте при этом разное количество деревьев (как минимум протестируйте следующие значения для количества деревьев: 10, 20, 30). \n",
    "\n",
    "Долго ли настраивались классификаторы? \n",
    "\n",
    "Достигнут ли оптимум на испытанных значениях параметра n_estimators, или же качество, скорее всего, продолжит расти при дальнейшем его увеличении?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрика качества\n",
    "\n",
    "В качестве метрики качества мы будем использовать площадь под ROC-кривой (AUC-ROC). Обратите внимание, что AUC-ROC — это метрика качества для алгоритма, выдающего оценки принадлежности первому классу. Оба алгоритма, которые будут использоваться в проекте — градиентный бустинг, и логистическая регрессия — умеют выдавать такие оценки. Для этого нужно получать предсказания с помощью функции predict_proba. Она возвращает два столбца: первый содержит оценки принадлежности нулевому классу, второй — первому классу. Вам нужны значения из второго столбца:\n",
    "```python\n",
    "pred = clf.predict_proba(X_test)[:, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = []\n",
    "# for max_depth in [8, 16, 32]:\n",
    "for lr in [0.3, 0.5, 0.7]:\n",
    "    for n_trees in [10, 20, 30, 40, 50, 60, 70]:\n",
    "        start_time = datetime.datetime.now()\n",
    "        clf = GradientBoostingClassifier(n_estimators=n_trees, random_state=42, learning_rate=lr)\n",
    "        clf.fit(X_train, y_train)\n",
    "        sc = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=kf).mean()   \n",
    "        pred = clf.predict_proba(X_train)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_train, pred)\n",
    "        d1.append([lr, n_trees, sc, roc_auc, datetime.datetime.now() - start_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cross_val_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_trees</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">0.3</th>\n",
       "      <th>10</th>\n",
       "      <td>0.631081</td>\n",
       "      <td>0.693715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.640070</td>\n",
       "      <td>0.707831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.644606</td>\n",
       "      <td>0.716298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.646107</td>\n",
       "      <td>0.722258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.647948</td>\n",
       "      <td>0.726873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.649367</td>\n",
       "      <td>0.731164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.650334</td>\n",
       "      <td>0.735176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">0.5</th>\n",
       "      <th>10</th>\n",
       "      <td>0.632994</td>\n",
       "      <td>0.695356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.642055</td>\n",
       "      <td>0.712190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.646210</td>\n",
       "      <td>0.720849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.648113</td>\n",
       "      <td>0.728116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.650273</td>\n",
       "      <td>0.733339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.650653</td>\n",
       "      <td>0.737985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.650324</td>\n",
       "      <td>0.742849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">0.7</th>\n",
       "      <th>10</th>\n",
       "      <td>0.632696</td>\n",
       "      <td>0.697128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.641222</td>\n",
       "      <td>0.714645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.643659</td>\n",
       "      <td>0.723850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.645449</td>\n",
       "      <td>0.730980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.737307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.647547</td>\n",
       "      <td>0.742657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.647496</td>\n",
       "      <td>0.747330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cross_val_score   roc_auc\n",
       "learning_rate n_trees                           \n",
       "0.3           10              0.631081  0.693715\n",
       "              20              0.640070  0.707831\n",
       "              30              0.644606  0.716298\n",
       "              40              0.646107  0.722258\n",
       "              50              0.647948  0.726873\n",
       "              60              0.649367  0.731164\n",
       "              70              0.650334  0.735176\n",
       "0.5           10              0.632994  0.695356\n",
       "              20              0.642055  0.712190\n",
       "              30              0.646210  0.720849\n",
       "              40              0.648113  0.728116\n",
       "              50              0.650273  0.733339\n",
       "              60              0.650653  0.737985\n",
       "              70              0.650324  0.742849\n",
       "0.7           10              0.632696  0.697128\n",
       "              20              0.641222  0.714645\n",
       "              30              0.643659  0.723850\n",
       "              40              0.645449  0.730980\n",
       "              50              0.646303  0.737307\n",
       "              60              0.647547  0.742657\n",
       "              70              0.647496  0.747330"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1_df = pd.DataFrame(d1, columns=['learning_rate', 'n_trees', 'cross_val_score', 'roc_auc', 'time_elapsed'])\n",
    "d1_df.pivot_table(index=['learning_rate', 'n_trees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6506530906098942\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_trees</th>\n",
       "      <th>cross_val_score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>time_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.631081</td>\n",
       "      <td>0.693715</td>\n",
       "      <td>0 days 00:01:18.944152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.640070</td>\n",
       "      <td>0.707831</td>\n",
       "      <td>0 days 00:02:37.396168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.644606</td>\n",
       "      <td>0.716298</td>\n",
       "      <td>0 days 00:03:53.554117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>40</td>\n",
       "      <td>0.646107</td>\n",
       "      <td>0.722258</td>\n",
       "      <td>0 days 00:05:08.676206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.647948</td>\n",
       "      <td>0.726873</td>\n",
       "      <td>0 days 00:06:27.814513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>60</td>\n",
       "      <td>0.649367</td>\n",
       "      <td>0.731164</td>\n",
       "      <td>0 days 00:07:44.944800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3</td>\n",
       "      <td>70</td>\n",
       "      <td>0.650334</td>\n",
       "      <td>0.735176</td>\n",
       "      <td>0 days 00:09:01.499899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.632994</td>\n",
       "      <td>0.695356</td>\n",
       "      <td>0 days 00:01:17.903145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.642055</td>\n",
       "      <td>0.712190</td>\n",
       "      <td>0 days 00:02:36.821421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.646210</td>\n",
       "      <td>0.720849</td>\n",
       "      <td>0 days 00:03:58.860585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.648113</td>\n",
       "      <td>0.728116</td>\n",
       "      <td>0 days 00:05:21.587135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.650273</td>\n",
       "      <td>0.733339</td>\n",
       "      <td>0 days 00:06:38.024903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>60</td>\n",
       "      <td>0.650653</td>\n",
       "      <td>0.737985</td>\n",
       "      <td>0 days 00:07:59.715543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>70</td>\n",
       "      <td>0.650324</td>\n",
       "      <td>0.742849</td>\n",
       "      <td>0 days 00:09:22.902636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.632696</td>\n",
       "      <td>0.697128</td>\n",
       "      <td>0 days 00:01:20.488537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.641222</td>\n",
       "      <td>0.714645</td>\n",
       "      <td>0 days 00:02:39.248898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.7</td>\n",
       "      <td>30</td>\n",
       "      <td>0.643659</td>\n",
       "      <td>0.723850</td>\n",
       "      <td>0 days 00:04:02.405193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.7</td>\n",
       "      <td>40</td>\n",
       "      <td>0.645449</td>\n",
       "      <td>0.730980</td>\n",
       "      <td>0 days 00:05:43.431159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.737307</td>\n",
       "      <td>0 days 00:06:39.170381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.7</td>\n",
       "      <td>60</td>\n",
       "      <td>0.647547</td>\n",
       "      <td>0.742657</td>\n",
       "      <td>0 days 00:07:45.408546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.7</td>\n",
       "      <td>70</td>\n",
       "      <td>0.647496</td>\n",
       "      <td>0.747330</td>\n",
       "      <td>0 days 00:09:07.138248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  n_trees  cross_val_score   roc_auc           time_elapsed\n",
       "0             0.3       10         0.631081  0.693715 0 days 00:01:18.944152\n",
       "1             0.3       20         0.640070  0.707831 0 days 00:02:37.396168\n",
       "2             0.3       30         0.644606  0.716298 0 days 00:03:53.554117\n",
       "3             0.3       40         0.646107  0.722258 0 days 00:05:08.676206\n",
       "4             0.3       50         0.647948  0.726873 0 days 00:06:27.814513\n",
       "5             0.3       60         0.649367  0.731164 0 days 00:07:44.944800\n",
       "6             0.3       70         0.650334  0.735176 0 days 00:09:01.499899\n",
       "7             0.5       10         0.632994  0.695356 0 days 00:01:17.903145\n",
       "8             0.5       20         0.642055  0.712190 0 days 00:02:36.821421\n",
       "9             0.5       30         0.646210  0.720849 0 days 00:03:58.860585\n",
       "10            0.5       40         0.648113  0.728116 0 days 00:05:21.587135\n",
       "11            0.5       50         0.650273  0.733339 0 days 00:06:38.024903\n",
       "12            0.5       60         0.650653  0.737985 0 days 00:07:59.715543\n",
       "13            0.5       70         0.650324  0.742849 0 days 00:09:22.902636\n",
       "14            0.7       10         0.632696  0.697128 0 days 00:01:20.488537\n",
       "15            0.7       20         0.641222  0.714645 0 days 00:02:39.248898\n",
       "16            0.7       30         0.643659  0.723850 0 days 00:04:02.405193\n",
       "17            0.7       40         0.645449  0.730980 0 days 00:05:43.431159\n",
       "18            0.7       50         0.646303  0.737307 0 days 00:06:39.170381\n",
       "19            0.7       60         0.647547  0.742657 0 days 00:07:45.408546\n",
       "20            0.7       70         0.647496  0.747330 0 days 00:09:07.138248"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(d1_df.cross_val_score.max())\n",
    "d1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for lr in d1_df.learning_rate.unique():\n",
    "    plt.plot(d1_df[d1_df.learning_rate == lr].n_trees, d1_df[d1_df.learning_rate == lr].cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for lr in d1_df.learning_rate.unique():\n",
    "    plt.plot(d1_df[d1_df.learning_rate == lr].n_trees, d1_df[d1_df.learning_rate == lr].time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также есть и другие подходы — например, замена пропуска на среднее значение признака. Мы не требуем этого в задании, но при желании попробуйте разные подходы к обработке пропусков и сравните их между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6490280777537797 0:06:26.984192\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "clf = GradientBoostingClassifier(n_estimators=50, random_state=42, learning_rate=0.5)\n",
    "clf.fit(X_train_var2, y_train)\n",
    "sc = cross_val_score(estimator=clf, X=X_train_var2, y=y_train, cv=kf).mean()   \n",
    "print(sc, datetime.datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимум практически достигнут при значении параметра n_estimators = 50. При дальнейшем его увеличении качество практически не растёт.\n",
    "**Длительность** обучения классификатора **растёт линейно с увеличением параметра n_estimators**.\n",
    "\n",
    "**В итоге** на CPU Intel Xeon 55555 при n_estimators=50 и learning_rate=0.5 расчёт занял 6 мин и качество составило **0.65** \n",
    "\n",
    "Замена пропуска на среднее значение признака увеличение качества не дала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Использование алгоритма XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(learning_rate=0.5, n_estimators=50, random_state=42, \n",
    "                     eval_metric='rmse', use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold CV average score: 0.638, roc_auc: 0.829, time elapsed: 0:01:44.946013\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "xgbc.fit(X_train, y_train)\n",
    "sc = cross_val_score(estimator=xgbc, X=X_train, y=y_train, cv=kf).mean()\n",
    "pred = xgbc.predict_proba(X_train)[:, 1]\n",
    "roc_auc = roc_auc_score(y_train, pred)\n",
    "print(\"K-fold CV average score: %.3f, roc_auc: %.3f, time elapsed: %s\" % \n",
    "      (sc, roc_auc, datetime.datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм **XGBoost** показал более высокое быстродействие при сохранении качества. Результат **0.64** за 2 мин. ROC AUC = 0.83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Использование алгоритма XGBoost на GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for max_depth in [8, 16, 32]:\n",
    "xgbc = XGBClassifier(tree_method='gpu_hist', gpu_id=0,\n",
    "                     learning_rate=0.5, n_estimators=50, random_state=42,\n",
    "                     eval_metric='rmse', use_label_encoder=False)\n",
    "start_time = datetime.datetime.now()\n",
    "xgbc.fit(X_train, y_train)\n",
    "sc = cross_val_score(estimator=xgbc, X=X_train, y=y_train, cv=kf).mean()\n",
    "pred = xgbc.predict_proba(X_train)[:, 1]\n",
    "roc_auc = roc_auc_score(y_train, pred)\n",
    "print(\"K-fold CV average score: %.3f, roc_auc: %.3f, time elapsed: %s\" % \n",
    "      (sc, roc_auc, datetime.datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В результате** на GPU Nvidia GT 1030 при n_estimators=50 и learning_rate=0.5 расчёт занял 1 мин и качество составило **0.65** ROC AUC = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подход 2: логистическая регрессия\n",
    "\n",
    "Линейные методы работают гораздо быстрее композиций деревьев, поэтому кажется разумным воспользоваться именно ими для ускорения анализа данных. Одним из наиболее распространенных методов для классификации является логистическая регрессия.\n",
    "\n",
    "**Важно:** не забывайте, что линейные алгоритмы чувствительны к масштабу признаков! Может пригодиться sklearn.preprocessing.StandartScaler.\n",
    "\n",
    "1. **DONE** Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (C). Какое наилучшее качество у вас получилось? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?\n",
    "2. **DONE** Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Изменилось ли качество? Чем вы можете это объяснить?\n",
    "3. **DONE** На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts).\n",
    "4. Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. Ниже вы можете найти код, который выполняет данной преобразование. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа.\n",
    "5. Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Какое получилось качество? Улучшилось ли оно? Чем вы можете это объяснить?\n",
    "6. Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации). Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой (т.е. что модель не получилась константной).\n",
    "\n",
    "##### Что указать в отчете\n",
    "В отчете по данному этапу вы должны ответить на следующие вопросы:\n",
    "1. Какое качество получилось у логистической регрессии над всеми исходными признаками? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?\n",
    "2. Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем вы можете объяснить это изменение?\n",
    "3. Сколько различных идентификаторов героев существует в данной игре?\n",
    "4. Какое получилось качество при добавлении \"мешка слов\" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете это объяснить?\n",
    "5. Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in X_train.columns:\n",
    "#     print(X_train[col].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandardScaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.544364</td>\n",
       "      <td>1.540688</td>\n",
       "      <td>-1.244228</td>\n",
       "      <td>1.400808</td>\n",
       "      <td>1.525972</td>\n",
       "      <td>0.734957</td>\n",
       "      <td>0.969743</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>-0.578083</td>\n",
       "      <td>-0.509023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>1.066448</td>\n",
       "      <td>-0.041743</td>\n",
       "      <td>-0.262922</td>\n",
       "      <td>0.640648</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.562864</td>\n",
       "      <td>-0.551154</td>\n",
       "      <td>1.846004</td>\n",
       "      <td>-1.121494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.540452</td>\n",
       "      <td>-0.927798</td>\n",
       "      <td>-0.292258</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>-0.080139</td>\n",
       "      <td>-0.247570</td>\n",
       "      <td>-0.246859</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>1.017574</td>\n",
       "      <td>1.492930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>-0.338591</td>\n",
       "      <td>0.578946</td>\n",
       "      <td>-0.262922</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>1.066668</td>\n",
       "      <td>0.562864</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>0.437788</td>\n",
       "      <td>0.043947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.539231</td>\n",
       "      <td>1.540688</td>\n",
       "      <td>-0.568637</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>0.151070</td>\n",
       "      <td>0.263085</td>\n",
       "      <td>1.190944</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>-0.578083</td>\n",
       "      <td>1.492930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391203</td>\n",
       "      <td>-0.823968</td>\n",
       "      <td>-0.824352</td>\n",
       "      <td>0.158654</td>\n",
       "      <td>0.640648</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.562864</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>0.437788</td>\n",
       "      <td>0.490286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.532622</td>\n",
       "      <td>-0.575157</td>\n",
       "      <td>-0.691471</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>0.962950</td>\n",
       "      <td>-0.198013</td>\n",
       "      <td>0.306142</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>-0.578083</td>\n",
       "      <td>-1.309804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>-0.594053</td>\n",
       "      <td>0.241615</td>\n",
       "      <td>-0.022021</td>\n",
       "      <td>0.269135</td>\n",
       "      <td>-1.554868</td>\n",
       "      <td>0.562864</td>\n",
       "      <td>-0.551154</td>\n",
       "      <td>-0.970428</td>\n",
       "      <td>0.837439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.529221</td>\n",
       "      <td>1.540688</td>\n",
       "      <td>-1.182811</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>0.348745</td>\n",
       "      <td>-0.124754</td>\n",
       "      <td>-0.357459</td>\n",
       "      <td>0.968527</td>\n",
       "      <td>-0.578083</td>\n",
       "      <td>-0.108632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>1.347455</td>\n",
       "      <td>1.024223</td>\n",
       "      <td>-0.022021</td>\n",
       "      <td>0.680811</td>\n",
       "      <td>1.590976</td>\n",
       "      <td>-0.302485</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>-0.970428</td>\n",
       "      <td>-0.228816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97225</th>\n",
       "      <td>1.093978</td>\n",
       "      <td>-0.575157</td>\n",
       "      <td>-0.138714</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>0.834109</td>\n",
       "      <td>0.107949</td>\n",
       "      <td>0.637942</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>1.017574</td>\n",
       "      <td>-0.108632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>-0.568506</td>\n",
       "      <td>0.997237</td>\n",
       "      <td>0.218879</td>\n",
       "      <td>0.228972</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.562864</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>-0.970428</td>\n",
       "      <td>-0.427189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97226</th>\n",
       "      <td>1.096181</td>\n",
       "      <td>-0.927798</td>\n",
       "      <td>-0.261549</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>0.987660</td>\n",
       "      <td>0.577666</td>\n",
       "      <td>0.637942</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>1.017574</td>\n",
       "      <td>-1.309804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>0.044601</td>\n",
       "      <td>-1.431548</td>\n",
       "      <td>-0.142472</td>\n",
       "      <td>-1.578386</td>\n",
       "      <td>0.542361</td>\n",
       "      <td>-0.302485</td>\n",
       "      <td>-0.551154</td>\n",
       "      <td>-0.970428</td>\n",
       "      <td>-0.253612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97227</th>\n",
       "      <td>1.098746</td>\n",
       "      <td>-0.575157</td>\n",
       "      <td>1.427430</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>0.292267</td>\n",
       "      <td>-1.309820</td>\n",
       "      <td>-1.131661</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>-0.578083</td>\n",
       "      <td>-1.309804</td>\n",
       "      <td>...</td>\n",
       "      <td>1.769891</td>\n",
       "      <td>-0.645145</td>\n",
       "      <td>1.928271</td>\n",
       "      <td>0.580230</td>\n",
       "      <td>-1.578386</td>\n",
       "      <td>-1.030561</td>\n",
       "      <td>-2.033183</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>0.437788</td>\n",
       "      <td>-0.204019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97228</th>\n",
       "      <td>1.098952</td>\n",
       "      <td>-0.575157</td>\n",
       "      <td>1.488848</td>\n",
       "      <td>-0.398181</td>\n",
       "      <td>-0.173682</td>\n",
       "      <td>-0.822866</td>\n",
       "      <td>-0.578660</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>2.613231</td>\n",
       "      <td>-0.909413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>-0.364137</td>\n",
       "      <td>1.995737</td>\n",
       "      <td>-0.323147</td>\n",
       "      <td>0.259094</td>\n",
       "      <td>1.066668</td>\n",
       "      <td>-0.302485</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>0.437788</td>\n",
       "      <td>-0.873528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97229</th>\n",
       "      <td>1.102648</td>\n",
       "      <td>1.540688</td>\n",
       "      <td>-0.046588</td>\n",
       "      <td>-0.398181</td>\n",
       "      <td>-0.318409</td>\n",
       "      <td>-0.751762</td>\n",
       "      <td>-0.468060</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>-0.578083</td>\n",
       "      <td>-0.509023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>-0.747329</td>\n",
       "      <td>0.336068</td>\n",
       "      <td>1.242707</td>\n",
       "      <td>-1.578386</td>\n",
       "      <td>1.066668</td>\n",
       "      <td>-0.302485</td>\n",
       "      <td>-0.551154</td>\n",
       "      <td>-0.970428</td>\n",
       "      <td>-0.799138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97230 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0     -2.544364  1.540688 -1.244228  1.400808  1.525972  0.734957  0.969743   \n",
       "1     -2.540452 -0.927798 -0.292258  0.501314 -0.080139 -0.247570 -0.246859   \n",
       "2     -2.539231  1.540688 -0.568637  0.501314  0.151070  0.263085  1.190944   \n",
       "3     -2.532622 -0.575157 -0.691471  0.501314  0.962950 -0.198013  0.306142   \n",
       "4     -2.529221  1.540688 -1.182811  0.501314  0.348745 -0.124754 -0.357459   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "97225  1.093978 -0.575157 -0.138714  0.501314  0.834109  0.107949  0.637942   \n",
       "97226  1.096181 -0.927798 -0.261549  0.501314  0.987660  0.577666  0.637942   \n",
       "97227  1.098746 -0.575157  1.427430  0.501314  0.292267 -1.309820 -1.131661   \n",
       "97228  1.098952 -0.575157  1.488848 -0.398181 -0.173682 -0.822866 -0.578660   \n",
       "97229  1.102648  1.540688 -0.046588 -0.398181 -0.318409 -0.751762 -0.468060   \n",
       "\n",
       "            7         8         9    ...       92        93        94   \\\n",
       "0     -0.537757 -0.578083 -0.509023  ... -0.987486  1.066448 -0.041743   \n",
       "1     -0.537757  1.017574  1.492930  ... -0.987486 -0.338591  0.578946   \n",
       "2     -0.537757 -0.578083  1.492930  ...  0.391203 -0.823968 -0.824352   \n",
       "3     -0.537757 -0.578083 -1.309804  ... -0.987486 -0.594053  0.241615   \n",
       "4      0.968527 -0.578083 -0.108632  ... -0.987486  1.347455  1.024223   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "97225 -0.537757  1.017574 -0.108632  ... -0.987486 -0.568506  0.997237   \n",
       "97226 -0.537757  1.017574 -1.309804  ... -0.987486  0.044601 -1.431548   \n",
       "97227 -0.537757 -0.578083 -1.309804  ...  1.769891 -0.645145  1.928271   \n",
       "97228 -0.537757  2.613231 -0.909413  ... -0.987486 -0.364137  1.995737   \n",
       "97229 -0.537757 -0.578083 -0.509023  ... -0.987486 -0.747329  0.336068   \n",
       "\n",
       "            95        96        97        98        99        100       101  \n",
       "0     -0.262922  0.640648  0.018054  0.562864 -0.551154  1.846004 -1.121494  \n",
       "1     -0.262922  0.379585  1.066668  0.562864  0.678170  0.437788  0.043947  \n",
       "2      0.158654  0.640648  0.018054  0.562864  0.678170  0.437788  0.490286  \n",
       "3     -0.022021  0.269135 -1.554868  0.562864 -0.551154 -0.970428  0.837439  \n",
       "4     -0.022021  0.680811  1.590976 -0.302485  0.678170 -0.970428 -0.228816  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "97225  0.218879  0.228972  0.018054  0.562864  0.678170 -0.970428 -0.427189  \n",
       "97226 -0.142472 -1.578386  0.542361 -0.302485 -0.551154 -0.970428 -0.253612  \n",
       "97227  0.580230 -1.578386 -1.030561 -2.033183  0.678170  0.437788 -0.204019  \n",
       "97228 -0.323147  0.259094  1.066668 -0.302485  0.678170  0.437788 -0.873528  \n",
       "97229  1.242707 -1.578386  1.066668 -0.302485 -0.551154 -0.970428 -0.799138  \n",
       "\n",
       "[97230 rows x 102 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (C). Какое наилучшее качество у вас получилось? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression?\n",
    "# LogisticRegression(\n",
    "#     penalty='l2',\n",
    "#     *,\n",
    "#     dual=False,\n",
    "#     tol=0.0001,\n",
    "#     C=1.0,\n",
    "#     fit_intercept=True,\n",
    "#     intercept_scaling=1,\n",
    "#     class_weight=None,\n",
    "#     random_state=None,\n",
    "#     solver='lbfgs',\n",
    "#     max_iter=100,\n",
    "#     multi_class='auto',\n",
    "#     verbose=0,\n",
    "#     warm_start=False,\n",
    "#     n_jobs=None,\n",
    "#     l1_ratio=None,\n",
    "# )\n",
    "\n",
    "# clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "# clf.predict(X[:2, :])\n",
    "\n",
    "# clf.predict_proba(X[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>cross_val_score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>time_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.655374</td>\n",
       "      <td>0.71799</td>\n",
       "      <td>0 days 00:00:04.465591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.655466</td>\n",
       "      <td>0.71799</td>\n",
       "      <td>0 days 00:00:04.322306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.655456</td>\n",
       "      <td>0.71799</td>\n",
       "      <td>0 days 00:00:04.385336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.655446</td>\n",
       "      <td>0.71799</td>\n",
       "      <td>0 days 00:00:04.363967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C  cross_val_score  roc_auc           time_elapsed\n",
       "0   0.1         0.655374  0.71799 0 days 00:00:04.465591\n",
       "1   1.0         0.655466  0.71799 0 days 00:00:04.322306\n",
       "2  10.0         0.655456  0.71799 0 days 00:00:04.385336\n",
       "3  50.0         0.655446  0.71799 0 days 00:00:04.363967"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = []\n",
    "for C in [0.1, 1, 10, 50]:\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = LogisticRegression(penalty='l2', C=C, random_state=42)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    sc = cross_val_score(estimator=clf, X=X_train_scaled, y=y_train, cv=kf).mean()   \n",
    "    pred = clf.predict_proba(X_train_scaled)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_train, pred)    \n",
    "    d1.append([C, sc, roc_auc, datetime.datetime.now() - start_time])\n",
    "d1_df = pd.DataFrame(d1, columns=['C', 'cross_val_score', 'roc_auc', 'time_elapsed'])\n",
    "d1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как оно соотносится с качеством градиентного бустинга? **Чем вы можете объяснить эту разницу?** Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?\n",
    "\n",
    "Hаилучшее качество получилось: cross_val_score=0.65, roc_auc=0.72 - что **сопоставимо с качеством градиентного бустинга**\n",
    "\n",
    "(только на XGBoost ROC AUC был выше - 0.83).\n",
    "\n",
    "Но время работы значительно меньше - всего 4 сек."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. Категориальных признаков в этой задаче одиннадцать: lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. Изменилось ли качество? Чем вы можете это объяснить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>r1_hero</th>\n",
       "      <th>d1_hero</th>\n",
       "      <th>r2_hero</th>\n",
       "      <th>d2_hero</th>\n",
       "      <th>r3_hero</th>\n",
       "      <th>d3_hero</th>\n",
       "      <th>r4_hero</th>\n",
       "      <th>d4_hero</th>\n",
       "      <th>r5_hero</th>\n",
       "      <th>d5_hero</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>42</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>105</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>49</td>\n",
       "      <td>88</td>\n",
       "      <td>67</td>\n",
       "      <td>79</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>98</td>\n",
       "      <td>66</td>\n",
       "      <td>20</td>\n",
       "      <td>86</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>96</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>102</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>69</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>72</td>\n",
       "      <td>25</td>\n",
       "      <td>93</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114402</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114403</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>72</td>\n",
       "      <td>26</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>110</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114404</th>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>112</td>\n",
       "      <td>55</td>\n",
       "      <td>81</td>\n",
       "      <td>59</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114405</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>59</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>39</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114406</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>99</td>\n",
       "      <td>19</td>\n",
       "      <td>106</td>\n",
       "      <td>84</td>\n",
       "      <td>87</td>\n",
       "      <td>69</td>\n",
       "      <td>112</td>\n",
       "      <td>20</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97230 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lobby_type  r1_hero  d1_hero  r2_hero  d2_hero  r3_hero  d3_hero  \\\n",
       "match_id                                                                     \n",
       "0                  7       11        4       67       42       29       21   \n",
       "1                  0       42       39       49       88       67       79   \n",
       "2                  7       33       22       98       66       20       86   \n",
       "3                  1       29       96       30       48       75       15   \n",
       "4                  7       13       26       27       69       30       22   \n",
       "...              ...      ...      ...      ...      ...      ...      ...   \n",
       "114402             1       47       26        7       19        1       93   \n",
       "114403             0       43       72       26       75        4        5   \n",
       "114404             1       98       28       11       39      112       55   \n",
       "114405             1      100       59       72        9       79       50   \n",
       "114406             7       50       99       19      106       84       87   \n",
       "\n",
       "          r4_hero  d4_hero  r5_hero  d5_hero  \n",
       "match_id                                      \n",
       "0              20       37      105       84  \n",
       "1              37        7       26       12  \n",
       "2              27       29        4       80  \n",
       "3              37      102       41       20  \n",
       "4              72       25       93        8  \n",
       "...           ...      ...      ...      ...  \n",
       "114402         21        3       71       28  \n",
       "114403         29       20      110       98  \n",
       "114404         81       59       50       31  \n",
       "114405         20       28       39      106  \n",
       "114406         69      112       20       97  \n",
       "\n",
       "[97230 rows x 11 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categ_features = ['lobby_type']\n",
    "for i in range(1, 6):\n",
    "    categ_features.append('r' + str(i) + '_hero')\n",
    "    categ_features.append('d' + str(i) + '_hero')\n",
    "X_train_ver3 = X_train.drop(categ_features, axis = 1)\n",
    "X_train[categ_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.544364</td>\n",
       "      <td>1.400808</td>\n",
       "      <td>1.525972</td>\n",
       "      <td>0.734957</td>\n",
       "      <td>0.969743</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>-0.578083</td>\n",
       "      <td>-0.509023</td>\n",
       "      <td>-0.332256</td>\n",
       "      <td>-0.625222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>1.066448</td>\n",
       "      <td>-0.041743</td>\n",
       "      <td>-0.262922</td>\n",
       "      <td>0.640648</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.562864</td>\n",
       "      <td>-0.551154</td>\n",
       "      <td>1.846004</td>\n",
       "      <td>-1.121494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.540452</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>-0.080139</td>\n",
       "      <td>-0.247570</td>\n",
       "      <td>-0.246859</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>1.017574</td>\n",
       "      <td>1.492930</td>\n",
       "      <td>0.578881</td>\n",
       "      <td>0.732454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>-0.338591</td>\n",
       "      <td>0.578946</td>\n",
       "      <td>-0.262922</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>1.066668</td>\n",
       "      <td>0.562864</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>0.437788</td>\n",
       "      <td>0.043947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.539231</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>0.151070</td>\n",
       "      <td>0.263085</td>\n",
       "      <td>1.190944</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>-0.578083</td>\n",
       "      <td>1.492930</td>\n",
       "      <td>-0.332256</td>\n",
       "      <td>0.224676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391203</td>\n",
       "      <td>-0.823968</td>\n",
       "      <td>-0.824352</td>\n",
       "      <td>0.158654</td>\n",
       "      <td>0.640648</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.562864</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>0.437788</td>\n",
       "      <td>0.490286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.532622</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>0.962950</td>\n",
       "      <td>-0.198013</td>\n",
       "      <td>0.306142</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>-0.578083</td>\n",
       "      <td>-1.309804</td>\n",
       "      <td>-1.243393</td>\n",
       "      <td>-1.170813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>-0.594053</td>\n",
       "      <td>0.241615</td>\n",
       "      <td>-0.022021</td>\n",
       "      <td>0.269135</td>\n",
       "      <td>-1.554868</td>\n",
       "      <td>0.562864</td>\n",
       "      <td>-0.551154</td>\n",
       "      <td>-0.970428</td>\n",
       "      <td>0.837439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.529221</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>0.348745</td>\n",
       "      <td>-0.124754</td>\n",
       "      <td>-0.357459</td>\n",
       "      <td>0.968527</td>\n",
       "      <td>-0.578083</td>\n",
       "      <td>-0.108632</td>\n",
       "      <td>-1.243393</td>\n",
       "      <td>-1.008757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>1.347455</td>\n",
       "      <td>1.024223</td>\n",
       "      <td>-0.022021</td>\n",
       "      <td>0.680811</td>\n",
       "      <td>1.590976</td>\n",
       "      <td>-0.302485</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>-0.970428</td>\n",
       "      <td>-0.228816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97225</th>\n",
       "      <td>1.093978</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>0.834109</td>\n",
       "      <td>0.107949</td>\n",
       "      <td>0.637942</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>1.017574</td>\n",
       "      <td>-0.108632</td>\n",
       "      <td>-1.243393</td>\n",
       "      <td>-1.032165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>-0.568506</td>\n",
       "      <td>0.997237</td>\n",
       "      <td>0.218879</td>\n",
       "      <td>0.228972</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.562864</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>-0.970428</td>\n",
       "      <td>-0.427189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97226</th>\n",
       "      <td>1.096181</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>0.987660</td>\n",
       "      <td>0.577666</td>\n",
       "      <td>0.637942</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>1.017574</td>\n",
       "      <td>-1.309804</td>\n",
       "      <td>-0.332256</td>\n",
       "      <td>-0.765671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>0.044601</td>\n",
       "      <td>-1.431548</td>\n",
       "      <td>-0.142472</td>\n",
       "      <td>-1.578386</td>\n",
       "      <td>0.542361</td>\n",
       "      <td>-0.302485</td>\n",
       "      <td>-0.551154</td>\n",
       "      <td>-0.970428</td>\n",
       "      <td>-0.253612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97227</th>\n",
       "      <td>1.098746</td>\n",
       "      <td>0.501314</td>\n",
       "      <td>0.292267</td>\n",
       "      <td>-1.309820</td>\n",
       "      <td>-1.131661</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>-0.578083</td>\n",
       "      <td>-1.309804</td>\n",
       "      <td>0.578881</td>\n",
       "      <td>0.465961</td>\n",
       "      <td>...</td>\n",
       "      <td>1.769891</td>\n",
       "      <td>-0.645145</td>\n",
       "      <td>1.928271</td>\n",
       "      <td>0.580230</td>\n",
       "      <td>-1.578386</td>\n",
       "      <td>-1.030561</td>\n",
       "      <td>-2.033183</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>0.437788</td>\n",
       "      <td>-0.204019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97228</th>\n",
       "      <td>1.098952</td>\n",
       "      <td>-0.398181</td>\n",
       "      <td>-0.173682</td>\n",
       "      <td>-0.822866</td>\n",
       "      <td>-0.578660</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>2.613231</td>\n",
       "      <td>-0.909413</td>\n",
       "      <td>1.490017</td>\n",
       "      <td>1.377080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>-0.364137</td>\n",
       "      <td>1.995737</td>\n",
       "      <td>-0.323147</td>\n",
       "      <td>0.259094</td>\n",
       "      <td>1.066668</td>\n",
       "      <td>-0.302485</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>0.437788</td>\n",
       "      <td>-0.873528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97229</th>\n",
       "      <td>1.102648</td>\n",
       "      <td>-0.398181</td>\n",
       "      <td>-0.318409</td>\n",
       "      <td>-0.751762</td>\n",
       "      <td>-0.468060</td>\n",
       "      <td>-0.537757</td>\n",
       "      <td>-0.578083</td>\n",
       "      <td>-0.509023</td>\n",
       "      <td>1.490017</td>\n",
       "      <td>1.634571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987486</td>\n",
       "      <td>-0.747329</td>\n",
       "      <td>0.336068</td>\n",
       "      <td>1.242707</td>\n",
       "      <td>-1.578386</td>\n",
       "      <td>1.066668</td>\n",
       "      <td>-0.302485</td>\n",
       "      <td>-0.551154</td>\n",
       "      <td>-0.970428</td>\n",
       "      <td>-0.799138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97230 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0     -2.544364  1.400808  1.525972  0.734957  0.969743 -0.537757 -0.578083   \n",
       "1     -2.540452  0.501314 -0.080139 -0.247570 -0.246859 -0.537757  1.017574   \n",
       "2     -2.539231  0.501314  0.151070  0.263085  1.190944 -0.537757 -0.578083   \n",
       "3     -2.532622  0.501314  0.962950 -0.198013  0.306142 -0.537757 -0.578083   \n",
       "4     -2.529221  0.501314  0.348745 -0.124754 -0.357459  0.968527 -0.578083   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "97225  1.093978  0.501314  0.834109  0.107949  0.637942 -0.537757  1.017574   \n",
       "97226  1.096181  0.501314  0.987660  0.577666  0.637942 -0.537757  1.017574   \n",
       "97227  1.098746  0.501314  0.292267 -1.309820 -1.131661 -0.537757 -0.578083   \n",
       "97228  1.098952 -0.398181 -0.173682 -0.822866 -0.578660 -0.537757  2.613231   \n",
       "97229  1.102648 -0.398181 -0.318409 -0.751762 -0.468060 -0.537757 -0.578083   \n",
       "\n",
       "             7         8         9   ...        81        82        83  \\\n",
       "0     -0.509023 -0.332256 -0.625222  ... -0.987486  1.066448 -0.041743   \n",
       "1      1.492930  0.578881  0.732454  ... -0.987486 -0.338591  0.578946   \n",
       "2      1.492930 -0.332256  0.224676  ...  0.391203 -0.823968 -0.824352   \n",
       "3     -1.309804 -1.243393 -1.170813  ... -0.987486 -0.594053  0.241615   \n",
       "4     -0.108632 -1.243393 -1.008757  ... -0.987486  1.347455  1.024223   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "97225 -0.108632 -1.243393 -1.032165  ... -0.987486 -0.568506  0.997237   \n",
       "97226 -1.309804 -0.332256 -0.765671  ... -0.987486  0.044601 -1.431548   \n",
       "97227 -1.309804  0.578881  0.465961  ...  1.769891 -0.645145  1.928271   \n",
       "97228 -0.909413  1.490017  1.377080  ... -0.987486 -0.364137  1.995737   \n",
       "97229 -0.509023  1.490017  1.634571  ... -0.987486 -0.747329  0.336068   \n",
       "\n",
       "             84        85        86        87        88        89        90  \n",
       "0     -0.262922  0.640648  0.018054  0.562864 -0.551154  1.846004 -1.121494  \n",
       "1     -0.262922  0.379585  1.066668  0.562864  0.678170  0.437788  0.043947  \n",
       "2      0.158654  0.640648  0.018054  0.562864  0.678170  0.437788  0.490286  \n",
       "3     -0.022021  0.269135 -1.554868  0.562864 -0.551154 -0.970428  0.837439  \n",
       "4     -0.022021  0.680811  1.590976 -0.302485  0.678170 -0.970428 -0.228816  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "97225  0.218879  0.228972  0.018054  0.562864  0.678170 -0.970428 -0.427189  \n",
       "97226 -0.142472 -1.578386  0.542361 -0.302485 -0.551154 -0.970428 -0.253612  \n",
       "97227  0.580230 -1.578386 -1.030561 -2.033183  0.678170  0.437788 -0.204019  \n",
       "97228 -0.323147  0.259094  1.066668 -0.302485  0.678170  0.437788 -0.873528  \n",
       "97229  1.242707 -1.578386  1.066668 -0.302485 -0.551154 -0.970428 -0.799138  \n",
       "\n",
       "[97230 rows x 91 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ver3_scaled = pd.DataFrame(scaler.fit_transform(X_train_ver3))\n",
    "X_train_ver3_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>cross_val_score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>time_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.654983</td>\n",
       "      <td>0.717847</td>\n",
       "      <td>0 days 00:00:04.053584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.655004</td>\n",
       "      <td>0.717846</td>\n",
       "      <td>0 days 00:00:04.004401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.655024</td>\n",
       "      <td>0.717847</td>\n",
       "      <td>0 days 00:00:03.989382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C  cross_val_score   roc_auc           time_elapsed\n",
       "0   0.1         0.654983  0.717847 0 days 00:00:04.053584\n",
       "1   1.0         0.655004  0.717846 0 days 00:00:04.004401\n",
       "2  10.0         0.655024  0.717847 0 days 00:00:03.989382"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = []\n",
    "for C in [0.1, 1, 10]:\n",
    "    start_time = datetime.datetime.now()\n",
    "    clf = LogisticRegression(penalty='l2', C=C, random_state=42)\n",
    "    clf.fit(X_train_ver3_scaled, y_train)\n",
    "    sc = cross_val_score(estimator=clf, X=X_train_ver3_scaled, y=y_train, cv=kf).mean()   \n",
    "    pred = clf.predict_proba(X_train_ver3_scaled)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_train, pred)    \n",
    "    d1.append([C, sc, roc_auc, datetime.datetime.now() - start_time])\n",
    "d1_df = pd.DataFrame(d1, columns=['C', 'cross_val_score', 'roc_auc', 'time_elapsed'])\n",
    "d1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, какие именно герои играли за каждую команду. Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "heroes = []\n",
    "for col in categ_features:\n",
    "    heroes.extend(X_train[col].unique())\n",
    "N = len(np.unique(heroes))\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся подходом \"мешок слов\" для кодирования информации о героях. Пусть всего в игре имеет N различных героев. Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. Ниже вы можете найти код, который выполняет данное преобразование. Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа.\n",
    "\n",
    "\n",
    "##### Код для формирования \"мешка слов\" по героям\n",
    "```python\n",
    "# N — количество различных героев в выборке\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in xrange(5):\n",
    "        X_pick[i, data.ix[match_id, 'r%d_hero' % (p + 1)] - 1] = 1\n",
    "        X_pick[i, data.ix[match_id, 'd%d_hero' % (p + 1)] - 1] = -1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'ix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-58ff09e8ac1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mX_pick\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r%d_hero'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mX_pick\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'd%d_hero'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_pick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'ix'"
     ]
    }
   ],
   "source": [
    "X_pick = np.zeros((objects_count, N))\n",
    "\n",
    "for i, match_id in enumerate(X_train.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, X_train.ix[match_id, 'r%d_hero' % (p + 1)] - 1] = 1\n",
    "        X_pick[i, X_train.ix[match_id, 'd%d_hero' % (p + 1)] - 1] = -1\n",
    "X_pick        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,      1,      2,      3,      4,      5,      8,      9,\n",
       "                11,     12,\n",
       "            ...\n",
       "            114396, 114397, 114399, 114400, 114401, 114402, 114403, 114404,\n",
       "            114405, 114406],\n",
       "           dtype='int64', name='match_id', length=97230)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка финальной модели\n",
    "\n",
    "После того как вы провели все эксперименты и выбрали лучшую модель, можете проверить ее качество на тестовых матчах.  В отличие от основного набора матчей, в тестовых матчах есть только та информация, которая известна на момент первых 5 игровых минут, результат матча — неизвестен. Таблица признаков для тестовых матчей — `features_test.csv`.\n",
    "\n",
    "Для всех матчей из тестового набора предскажите вероятность победы Radiant, запишите предсказания в CSV файл с колонками `match_id` (идентификатор матча) и `radiant_win` — предсказанная вероятность. Файл с предсказаниями должен выглядеть примерно следующим образом:\n",
    "\n",
    "```\n",
    "match_id,radiant_win\n",
    "1,0.51997370502\n",
    "4,0.51997370502\n",
    "15,0.51997370502\n",
    "...\n",
    "```\n",
    "\n",
    "Отправьте решение на Kaggle в соревнование: Dota 2: Win Probability Prediction.\n",
    "\n",
    "Ссылка на соревнование: [Dota 2: Win Probability Prediction](https://kaggle.com/join/coursera_ml_dota2_contest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer = \n",
    "# print(answer)\n",
    "# with open('lab_answ/final_statement.csv', 'w') as outfile:\n",
    "#     outfile.write(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что еще попробовать?\n",
    "\n",
    "Разумеется, можно попробовать еще очень много разных идей, которые помогут вам получить еще более высокий результат на kaggle. Вот лишь несколько возможных вариантов:\n",
    "1. Про каждого из игроков есть достаточно много показателей: максимальный опыт, число смертей и т.д. (см. список выше). Можно попробовать просуммировать или усредних их, получив агрегированные показатели для всей команды.\n",
    "2. В сырых данных (файл matches.jsonlines.bz2) содержится очень много информации, которую мы пока не использовали. Вы можете, например, составить \"мешки слов\" для покупок различных предметов (то есть кодировать информацию о том, сколько раз каждая команда покупала тот или иной предмет). Обратите внимание, что при этом вы можете получить слишком большое количество признаков, для которых может иметь смысл сделать понижение размерности с помощью метода главных компонент.\n",
    "3. Можно сформировать признаки про изменения способностей героев в течение матча (ability_upgrades).\n",
    "4. В этом задании используются только градиентный бустинг и логистическая регрессия — но ведь мы изучали и другие модели! Можно попробовать метод k ближайших соседей, SVM, случайный лес и так далее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование нейронной сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.set_device(0)\n",
    "#     torch.cuda.current_device()\n",
    "#     torch.cuda.device(0)\n",
    "#     torch.cuda.device_count()\n",
    "#     torch.cuda.get_device_name(0)\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "    \n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    \n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\" )\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузчики данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ds = torch.tensor(np.array(X_train))\n",
    "y_train_ds = torch.tensor(np.array(y_train))\n",
    "\n",
    "trainset = TensorDataset(X_train_ds, y_train_ds)\n",
    "  \n",
    "# implementing dataloader on the dataset \n",
    "trainloader = DataLoader(trainset, batch_size=5, shuffle=True)\n",
    "  \n",
    "# for i in dataloader:\n",
    "#     print(i)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Определение нейронной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() # Конструктор суперкласса\n",
    "        \n",
    "        # Описание слоёв:\n",
    "        nodes2 = features_count // 3\n",
    "        self.fc1 = nn.Linear(features_count, nodes2, bias=False) # Полносвязный слой первый аргумент — определение \n",
    "                                              # количества узлов в i-том слое, а второй — \n",
    "                                              # количество узлов в i+1 слое\n",
    "        nodes3 = nodes2 // 4\n",
    "        self.fc2 = nn.Linear(nodes2, nodes3, bias=False)     # Полносвязный слой\n",
    "        self.fc3 = nn.Linear(nodes3, 1, bias=False)          # Полносвязный слой\n",
    "\n",
    "    # Функция, описывающая поток данных при обучении и предсказании\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-eaac3806f32e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# summary(net, (3, 224, 224), device=\"cpu\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "# dataset = ld.load()\n",
    "# data_iter = Data.DataLoader(dataset, batch_size=168, shuffle=True)\n",
    "data_iter = trainloader\n",
    "# net = model.VGG_19()\n",
    "# summary(net, (3, 224, 224), device=\"cpu\")\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, dampening=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "for epoch in range(5):\n",
    "    print(\"epoch:\", epoch + 1)\n",
    "    train_loss = 0\n",
    "    for i, data in enumerate(data_iter, 0):\n",
    "        x, y = data\n",
    "        x = x.float()\n",
    "        y = y.long()\n",
    "        print(x.dtype)\n",
    "        optimizer.zero_grad()\n",
    "        out = net(x)\n",
    "        loss = loss_func(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(\"loss:\", train_loss / 100)\n",
    "            train_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Отправляем сеть на GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().double()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Определим функцию потерь и оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()  # Функция потерь. \n",
    "\n",
    "# Оптимизатор SGD - Стохастический градиентный оптимизатор. \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "\n",
    "# #         labels = labels.float()\n",
    "#         loss = loss_func(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # print statistics\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, i + 1, running_loss / 2000))\n",
    "#             running_loss = 0.0\n",
    "\n",
    "# print('Time elapsed:', datetime.datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка использования видеопамяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сохраняем обученную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './my_final_statement.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тестирование сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "# Загрузка параметров модели из файла\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)    # что значит _,  ?\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посмотрим, как сеть работает на всем наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():   # что значит no_grad() ?\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
